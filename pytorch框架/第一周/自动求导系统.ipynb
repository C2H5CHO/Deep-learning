{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、`torch.autograd.backward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.backward(\n",
    "#     tensor,\n",
    "#     grad_tensors=None,\n",
    "#     retain_graph=None,\n",
    "#     create_graph=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "功能：自动求取梯度\n",
    "\n",
    "- `tensors`：用于求导的张量\n",
    "- `retain_graph`：保存计算图\n",
    "- `create_graph`：创建导数计算图，用于高阶求导\n",
    "- `grad_tensors`：多梯度权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "$y = (x + w) * (w + 1)$\n",
    "\n",
    "$a = x + w$\n",
    "\n",
    "$b = w + 1$\n",
    "\n",
    "$y = a * b$\n",
    "\n",
    "$\\frac{∂y}{∂w} = \\frac{∂y}{∂a} \\frac{∂a}{∂w} + \\frac{∂y}{∂b} \\frac{∂b}{∂w} = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.]) tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    w = torch.tensor([1.],requires_grad=True)\n",
    "    x = torch.tensor([2.],requires_grad=True)\n",
    "\n",
    "    a = torch.add(w, x)\n",
    "    b = torch.add(w, 1)\n",
    "    y = torch.mul(a, b)\n",
    "\n",
    "    y.backward(retain_graph=True) # retain_graph=True表示不释放计算图\n",
    "    print(w.grad, x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.]) tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    w = torch.tensor([1.],requires_grad=True)\n",
    "    x = torch.tensor([2.],requires_grad=True)\n",
    "\n",
    "    a = torch.add(w, x)\n",
    "    b = torch.add(w, 1)\n",
    "    \n",
    "    y0 = torch.mul(a, b)\n",
    "    y1 = torch.add(a, b)\n",
    "\n",
    "    loss = torch.cat([y0, y1], dim=0)\n",
    "    grad_tensors = torch.tensor([1., 1.])\n",
    "    loss.backward(gradient=grad_tensors)\n",
    "    print(w.grad, x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、`torch.autograd.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.grad(\n",
    "#     outputs,\n",
    "#     inputs,\n",
    "#     grad_outputs=None,\n",
    "#     retain_graph=None,\n",
    "#     create_graph=False,\n",
    "#     only_inputs=True,\n",
    "#     allow_unused=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "功能：求取梯度\n",
    "- `outputs`：用于求导的张量\n",
    "- `inputs`：需要梯度的张量\n",
    "- `create_graph`：创建导数计算图，用于高阶求导\n",
    "- `retain_graph`：保存计算图\n",
    "- `grad_outputs`：多梯度权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([6.], grad_fn=<MulBackward0>),)\n",
      "(tensor([2.], grad_fn=<MulBackward0>),)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    x = torch.tensor([3.], requires_grad=True)\n",
    "    y = torch.pow(x, 2) # y = x^2\n",
    "\n",
    "    grad_1 = torch.autograd.grad(y, x, create_graph=True) # 计算y对x的导数\n",
    "    print(grad_1) # grad_1 = 2*x = 6\n",
    "    grad_2 = torch.autograd.grad(grad_1, x, create_graph=True) # 计算y对x的二阶导数\n",
    "    print(grad_2) # grad_2 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3、注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 梯度不自动清零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.]) tensor([2.])\n",
      "tensor([5.]) tensor([2.])\n",
      "tensor([5.]) tensor([2.])\n",
      "tensor([5.]) tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    w = torch.tensor([1.], requires_grad=True)\n",
    "    x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "    for i in range(4):\n",
    "        a = torch.add(w, x)\n",
    "        b = torch.add(w, 1)\n",
    "        y = torch.mul(a, b)\n",
    "\n",
    "        y.backward()\n",
    "        print(w.grad, x.grad)\n",
    "        \n",
    "        w.grad.zero_() # 清空梯度\n",
    "        x.grad.zero_() # 清空梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 依赖于叶子结点的结点，`requires_grad`默认为True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 叶子结点不可执行in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719495780496 tensor([1.])\n",
      "2719495881744 tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    a = torch.ones((1, ))\n",
    "    print(id(a), a)\n",
    "\n",
    "    a = a + torch.ones((1, ))\n",
    "    print(id(a), a) # 这里的a是一个新的tensor，和之前的a不是同一个tensor了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719495530336 tensor([1.])\n",
      "2719495530336 tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    a = torch.ones((1, ))\n",
    "    print(id(a), a)\n",
    "\n",
    "    a += torch.ones((1, ))\n",
    "    print(id(a), a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
